# Date: 25-02-26
Today I continued my focused learning on CPU performance and low level optimization by following the Performance Ninja playlist. The playlist contains 27 videos in total, and as of yesterday I have completed 13 of them. This helped me systematically build my understanding step by step instead of randomly jumping between topics.

I started by revising the fundamentals of ISA, CPU architecture, and microarchitecture. I clarified the difference between x86 and ARM as instruction set architectures and understood how microarchitecture refers to how a specific CPU implements that ISA internally. This cleared up earlier confusion where I was mixing these concepts.

Then I moved into core CPU performance concepts such as CPU cycles and IPC instructions per cycle. I understood how performance is not just about clock speed but also about how many instructions can be completed per cycle. I studied pipelining and how instructions are divided into stages to improve throughput. I also learned about branch prediction and how mispredictions cause pipeline stalls and reduce performance.

After that, I explored cache hierarchy including L1, L2, and L3 cache. I understood cache misses and memory latency, and how accessing main memory is significantly slower compared to cache. This gave me clarity on why memory bound problems behave differently from compute bound problems.

I then focused on SIMD and vectorization. I understood what AVX 256 means, where 256 refers to the width of the vector register in bits. I learned how intrinsic functions map closely to hardware instructions and why SIMD is preferred in many data parallel scenarios. I also studied C++ data types and their storage sizes, and how compiler flags like O3 and mavx2 enable aggressive optimizations and vector instructions.

I spent time understanding the structure of the Performance Ninja repository as well. I clarified why there are separate header and cpp files, how CMake works, and what it means to build a specific benchmark target. I understood what Google Benchmark is and how it automates performance measurement.

The main problems I faced were conceptual confusion between ISA and microarchitecture at the beginning. I also struggled to fully understand how additional ALUs relate to SIMD execution inside the CPU pipeline. There was some difficulty in understanding compiler flags and how they influence the generated machine code. I also had confusion about memory layout and struct optimization, especially around data type sizes like bool and memory packing. Additionally, I found it challenging to understand how separating outer loops improves performance in certain optimization examples.

Overall, yesterday was a productive learning day. By completing 13 out of 27 videos in the Performance Ninja playlist, I have covered nearly half of the series. I strengthened my foundation in CPU architecture, pipelining, caching, SIMD programming, compiler optimizations, and benchmarking. Even though I faced conceptual challenges, I was able to clarify most of them and develop a clearer understanding of how low level performance optimization works.
